{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymorphy2\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Из текста книги http://az.lib.ru/k/kipling_d_r/text_0070.shtml вырезать все лишнее не относящееся к тексту (лицензии и т.п.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопировал тескт книги в блокнот text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Найти top 100 самых часто используемые нормализованных слов в тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убираем знаки препинания с помощью модуля string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "text = text.translate(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализацию проведём с помощью морфологического анализатора pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    words = text.split()\n",
    "    res = list()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_text = lemmatize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все слова приведены в начальную форму, теперь необходимо убрать стоп-слова, загрузим их из nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('russian'))\n",
    "\n",
    "lemmatize_text_drop_stop = []\n",
    "for word in lemmatize_text: \n",
    "    if word not in stopwords.words('russian'):\n",
    "        lemmatize_text_drop_stop.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сопоставления слова и его частоты в тексте используем класс FreqDist (frequency distributions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "frequency_word_dist = FreqDist(lemmatize_text_drop_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для отбора топ-100 наиболее встречающихся в тексте слов есть метод most_common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('это', 313),\n",
       " ('сказать', 312),\n",
       " ('свой', 256),\n",
       " ('мауголь', 226),\n",
       " ('который', 200),\n",
       " ('человек', 195),\n",
       " ('мочь', 190),\n",
       " ('всё', 187),\n",
       " ('котик', 163),\n",
       " ('маленький', 148),\n",
       " ('весь', 144),\n",
       " ('слон', 132),\n",
       " ('знать', 120),\n",
       " ('джунгли', 118),\n",
       " ('голова', 118),\n",
       " ('время', 117),\n",
       " ('нагой', 114),\n",
       " ('большой', 111),\n",
       " ('мальчик', 109),\n",
       " ('багира', 102),\n",
       " ('волк', 98),\n",
       " ('бал', 95),\n",
       " ('риккитикки', 94),\n",
       " ('говорить', 92),\n",
       " ('тумая', 89),\n",
       " ('нога', 84),\n",
       " ('обезьяна', 83),\n",
       " ('место', 81),\n",
       " ('очень', 77),\n",
       " ('ещё', 76),\n",
       " ('шер', 76),\n",
       " ('хан', 76),\n",
       " ('глаз', 75),\n",
       " ('детёныш', 73),\n",
       " ('кал', 68),\n",
       " ('видеть', 67),\n",
       " ('стать', 67),\n",
       " ('дерево', 67),\n",
       " ('земля', 66),\n",
       " ('наш', 65),\n",
       " ('день', 64),\n",
       " ('стая', 63),\n",
       " ('твой', 61),\n",
       " ('смотреть', 61),\n",
       " ('акел', 61),\n",
       " ('морской', 59),\n",
       " ('каа', 58),\n",
       " ('слово', 56),\n",
       " ('мать', 54),\n",
       " ('заметить', 54),\n",
       " ('сторона', 54),\n",
       " ('молодой', 52),\n",
       " ('бояться', 51),\n",
       " ('змея', 51),\n",
       " ('ответить', 50),\n",
       " ('убить', 50),\n",
       " ('лошадь', 50),\n",
       " ('спросить', 49),\n",
       " ('отец', 48),\n",
       " ('год', 48),\n",
       " ('брат', 47),\n",
       " ('тигр', 46),\n",
       " ('старый', 46),\n",
       " ('друг', 46),\n",
       " ('хороший', 46),\n",
       " ('больший', 45),\n",
       " ('каждый', 45),\n",
       " ('вода', 45),\n",
       " ('дикий', 44),\n",
       " ('сделать', 43),\n",
       " ('конец', 43),\n",
       " ('голос', 43),\n",
       " ('человеческий', 42),\n",
       " ('тэдди', 42),\n",
       " ('самый', 41),\n",
       " ('чёрный', 41),\n",
       " ('ночь', 41),\n",
       " ('вместе', 40),\n",
       " ('должный', 40),\n",
       " ('пока', 40),\n",
       " ('лапа', 39),\n",
       " ('лежать', 39),\n",
       " ('жизнь', 39),\n",
       " ('делать', 39),\n",
       " ('шея', 39),\n",
       " ('услышать', 39),\n",
       " ('зуб', 38),\n",
       " ('трава', 38),\n",
       " ('вперёд', 38),\n",
       " ('дело', 38),\n",
       " ('наген', 38),\n",
       " ('дать', 37),\n",
       " ('думать', 37),\n",
       " ('народ', 37),\n",
       " ('спина', 37),\n",
       " ('мул', 37),\n",
       " ('хвост', 36),\n",
       " ('ребёнок', 36),\n",
       " ('посмотреть', 36),\n",
       " ('закон', 36)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_word_dist.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ-100 слов получены, но необходимо отметить, что 101 слово и несколько ещё тоже могут встречаться в тексте 36 раз и тогда однозначно выделить топ-100 не получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('хвост', 36)\n",
      "('ребёнок', 36)\n",
      "('посмотреть', 36)\n",
      "('закон', 36)\n",
      "('минута', 36)\n",
      "('подняться', 36)\n",
      "('остров', 36)\n",
      "('берег', 36)\n"
     ]
    }
   ],
   "source": [
    "for word_freq in frequency_word_dist.most_common():\n",
    "    if word_freq[1] == 36:\n",
    "        print(word_freq)\n",
    "    elif word_freq[1] < 36:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось 36 раз в тексте встречается 8 слов, это означает, что однозначно можно выделить топ-96 слов (отсекая встречаемость 37 и более раз) или топ-104 (отсекая встречаемость 36 и более раз)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Найти все формы слова для top 10 самых часто используемые нормализованных слов в тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь, где ключами будут нормализованные слова, а значениями - список различных форм слова встречающиеся в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_all_forms = {}\n",
    "for word_freq in frequency_word_dist.most_common(10):\n",
    "    top_10_all_forms[word_freq[0]] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним словарь с помощью метода normal_form из pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in set(text.lower().split()):\n",
    "    if morph.parse(word)[0].normal_form in top_10_all_forms:\n",
    "        top_10_all_forms[morph.parse(word)[0].normal_form].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это - ['этом', 'этим', 'этого', 'это']\n",
      "\n",
      "сказать - ['скажет', 'сказать', 'скажите', 'сказано', 'скажешь', 'скажи', 'сказав', 'сказала', 'сказало', 'сказал', 'сказали', 'сказанные', 'скажу']\n",
      "\n",
      "свой - ['своем', 'своей', 'своими', 'свой', 'своя', 'свое', 'своим', 'своему', 'своего', 'свою', 'своих', 'свои']\n",
      "\n",
      "мауголь - ['маугли']\n",
      "\n",
      "который - ['которой', 'который', 'которым', 'которое', 'котором', 'которую', 'которых', 'которого', 'которому', 'которая', 'которые']\n",
      "\n",
      "человек - ['людьми', 'человека', 'человеком', 'людям', 'человеку', 'человек', 'людях', 'людей', 'люди']\n",
      "\n",
      "мочь - ['могли', 'мог', 'можем', 'могут', 'могла', 'может', 'можете', 'могу', 'могло', 'можешь']\n",
      "\n",
      "всё - ['все']\n",
      "\n",
      "котик - ['котики', 'котику', 'котика', 'котикам', 'котиком', 'котиков', 'котик']\n",
      "\n",
      "маленький - ['меньше', 'маленькие', 'маленькое', 'маленького', 'мала', 'маленькому', 'маленьком', 'маленький', 'маленькая', 'маленьким', 'мал', 'маленькими', 'маленькой', 'маленьких']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word, all_forms in top_10_all_forms.items():\n",
    "    print(word, all_forms, sep=' - ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что имя \"Маугли\" встречается всего в одном тексте никакой алгоритм не сможет корректно с ним разобраться, если не внести его в словарь известных слов, что судя по всему в pymorphy2 не сделано."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Найти все имена собственные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска имён собственных воспользуемся тегом Name из pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_hold = 0.2\n",
    "\n",
    "proper_names = set()\n",
    "\n",
    "for word in lemmatize_text_drop_stop:\n",
    "    for p in morph.parse(word):\n",
    "        if 'Name' in p.tag and p.score >= thresh_hold:\n",
    "            proper_names.add(p.normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'абиссиния',\n",
       " 'агата',\n",
       " 'акел',\n",
       " 'алла',\n",
       " 'анна',\n",
       " 'арра',\n",
       " 'багир',\n",
       " 'багира',\n",
       " 'барак',\n",
       " 'бента',\n",
       " 'билли',\n",
       " 'биллимула',\n",
       " 'бутерина',\n",
       " 'гапур',\n",
       " 'георгий',\n",
       " 'дельфина',\n",
       " 'джидур',\n",
       " 'диганга',\n",
       " 'дик',\n",
       " 'дхак',\n",
       " 'кавнапур',\n",
       " 'карнак',\n",
       " 'карэта',\n",
       " 'кедда',\n",
       " 'кербайн',\n",
       " 'кербайна',\n",
       " 'керик',\n",
       " 'керика',\n",
       " 'кола',\n",
       " 'кханивар',\n",
       " 'кханхивар',\n",
       " 'лев',\n",
       " 'магдаля',\n",
       " 'маила',\n",
       " 'марешаля',\n",
       " 'мила',\n",
       " 'наген',\n",
       " 'нагена',\n",
       " 'надежда',\n",
       " 'ната',\n",
       " 'павел',\n",
       " 'павлин',\n",
       " 'паталамон',\n",
       " 'першад',\n",
       " 'пол',\n",
       " 'радж',\n",
       " 'ранна',\n",
       " 'роза',\n",
       " 'рой',\n",
       " 'салаа',\n",
       " 'самбхур',\n",
       " 'сахиба',\n",
       " 'тарана',\n",
       " 'теодор',\n",
       " 'тэдди',\n",
       " 'удейпур',\n",
       " 'усама',\n",
       " 'фернандес',\n",
       " 'хая',\n",
       " 'хромуля',\n",
       " 'хуан',\n",
       " 'худж',\n",
       " 'хукмхей',\n",
       " 'хулла',\n",
       " 'эрорулала',\n",
       " 'эррула'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понижение степени уверенности алгоритма (thresh_hold) ниже 0.2 приводит к появлению мусора в итоговом \"списке\" имён собственных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
